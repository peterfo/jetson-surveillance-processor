{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2-Jetson-Nano-v3-darknet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterfo/jetson-surveillance-processor/blob/master/Lab2_Jetson_Nano_v3_darknet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF95QLCk95Rb",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQWEF3GzmbA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define constants\n",
        "USE_GPU = True\n",
        "\n",
        "# Control if we do face detection and verification or not\n",
        "DO_FACE_DETECTION_VERIFICATION = False\n",
        "\n",
        "# Used for Object Detection\n",
        "#USE_RETINANET = 0\n",
        "#USE_YOLOV3 = 1\n",
        "#USE_TINYYOLOV3 = 2\n",
        "# Flag to control which model we use\n",
        "#MODEL_TO_USE = USE_RETINANET\n",
        "# Flag to control which resulting framerate we want\n",
        "RESULTING_FRAMERATE = 15\n",
        "# Control the threshold for Object Detection\n",
        "OBJDET_MIN_PERCENTAGE_PROBABILITY = 30\n",
        "#OBJDET_JETSON_MODEL_TO_USE = \"ssd-inception-v2\"\n",
        "OBJDET_JETSON_MODEL_TO_USE = \"ssd-mobilenet-v2\"\n",
        "OBJDET_VIDEO_FRAME_SKIP_RATE = 3\n",
        "OBJDET_OVERLAY_FLAG = \"--overlay=box,labels,conf\"\n",
        "OBJDET_TEMP_IMAGE_FILENAME = \"/tmp/ramdisk/temp_frame_img.jpg\"\n",
        "\n",
        "DARKNET_PATH = \"../git/darknet\"\n",
        "DARKNET_CFG = \"cfg/yolov3.cfg\"\n",
        "DARKNET_WEIGHTS = \"yolov3.weights\"\n",
        "DARKNET_META = \"cfg/coco.data\"\n",
        "\n",
        "# Control the skip rate for face detection in videos\n",
        "FACEDET_FRAME_SKIP_RATE = 5   # We look at every 5th frame. With FPS=15 this means \n",
        "                              # we will look for faces in 3 frames per second\n",
        "\n",
        "\n",
        "ACCESS_RIGHTS = 0o755  # define the access rights for new created directories\n",
        "\n",
        "# Root directories (CHANGE AS NEEDED)\n",
        "#INPUT_ROOT = \"./input/\"            # The input file tree we will process recursively\n",
        "#OUTPUT_ROOT = \"./output/\"          # Where we will put the predicted images & videos\n",
        "#PROCESSED_ROOT = \"./processed/\"    # Where we will move the files after processing\n",
        "PROCESSED_POS_OBJDET_SUBROOT = \"pos_objdet\"  # Added after PROCESSED_ROOT when object(s) detected\n",
        "PROCESSED_NEG_OBJDET_SUBROOT = \"neg_objdet\"  # Added after PROCESSED_ROOT when object(s) not detected\n",
        "PROCESSED_ERROR_SUBROOT = \"error\"            # Added after PROCESSED_ROOT when error occurred\n",
        "\n",
        "# The trees we process\n",
        "PROCESSING_TREES = [ [\"/mnt/samba/ovak/inne_uppe/\", \"/mnt/samba/ovak/output/inne_uppe/\", \"/mnt/samba/ovak/processed/inne_uppe/\"],\n",
        "                     [\"/mnt/samba/ovak/inne_nere/\", \"/mnt/samba/ovak/output/inne_nere/\", \"/mnt/samba/ovak/processed/inne_nere/\"],\n",
        "                     [\"/mnt/samba/ovak/inne_garage/\", \"/mnt/samba/ovak/output/inne_garage/\", \"/mnt/samba/ovak/processed/inne_garage/\"],\n",
        "                     [\"/mnt/samba/ovak/ute_fram/\", \"/mnt/samba/ovak/output/ute_fram/\", \"/mnt/samba/ovak/processed/ute_fram/\"],\n",
        "                     [\"/mnt/samba/ovak/ute_bak/\", \"/mnt/samba/ovak/output/ute_bak/\", \"/mnt/samba/ovak/processed/ute_bak/\"] ]\n",
        "\n",
        "LOGFILE_NAME = \"/mnt/samba/ovak/log.txt\"\n",
        "CSVFILE_NAME = \"/mnt/samba/ovak/log.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82p1H8hridNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global variables\n",
        "\n",
        "# These are used to pass info from the callback-function used for \n",
        "# Object Detection in videos\n",
        "person_max_prob_in_video = 0.0\n",
        "cat_max_prob_in_video = 0.0\n",
        "car_max_prob_in_video = 0.0\n",
        "truck_max_prob_in_video = 0.0\n",
        "motorcycle_max_prob_in_video = 0.0\n",
        "bicycle_max_prob_in_video = 0.0\n",
        "\n",
        "# These will be calculated in the main flow\n",
        "if DO_FACE_DETECTION_VERIFICATION:\n",
        "  p_face_embedding = None\n",
        "  m_face_embedding = None\n",
        "  s_face_embedding = None\n",
        "  l_face_embedding = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSXSPkG4-T2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if we are in Colab\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "print(\"IN_COLAB:\", IN_COLAB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4bm50wdyVJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import what we need\n",
        "import sys\n",
        "import os\n",
        "import errno\n",
        "import datetime\n",
        "import shutil\n",
        "import time\n",
        "from matplotlib import pyplot\n",
        "#import urllib\n",
        "#import urllib.request\n",
        "import cv2\n",
        "import numpy as np\n",
        "#from google.colab import files\n",
        "\n",
        "#import jetson.inference\n",
        "#import jetson.utils\n",
        "import darknet\n",
        "\n",
        "if DO_FACE_DETECTION_VERIFICATION:\n",
        "  import insightface\n",
        "  import mxnet\n",
        "  mxnet_num_gpus = mxnet.context.num_gpus()\n",
        "  print(\"mxnet.num_gpus() =\", mxnet_num_gpus)\n",
        "  for i in range(mxnet_num_gpus):\n",
        "    print(\"mxnet.gpu_memory_info(\", i, \") =\", mxnet.context.gpu_memory_info(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b96xrlrh-DC4",
        "colab_type": "text"
      },
      "source": [
        "## Define functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-7h6q125vMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to downscale an image (if needed), preserving aspect ratio\n",
        "def downscale_image(img, max_x, max_y):\n",
        "  x_ratio = max_x / img.shape[0]\n",
        "  y_ratio = max_y / img.shape[1]\n",
        "  #print(\"img.shape =\", img.shape)\n",
        "  #print(\"x_ratio =\", x_ratio, \"   y_ratio =\", y_ratio)\n",
        "  downscale_ratio = min(x_ratio, y_ratio)\n",
        "  if downscale_ratio < 1:\n",
        "    width = int(img.shape[1] * downscale_ratio)\n",
        "    height = int(img.shape[0] * downscale_ratio)\n",
        "    dim = (width, height)\n",
        "    # resize image\n",
        "    resized_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA) \n",
        "    #print(\"resized_img.shape =\", resized_img.shape)\n",
        "    return resized_img\n",
        "  else:\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUT70kxPbT88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to do face detection on an image and optionally save the\n",
        "# result to a new image file.\n",
        "# Return the faces, landmarks detected\n",
        "def detect_faces_and_save_results_img(input_image, model, output_filename = None):\n",
        "  # Downscale the image if needed\n",
        "  img = downscale_image(input_image, 1280, 1280)  # Max x size = 1280, max y size = 1280\n",
        "  # Do face detection on input image, with original resolution and threshold 0.5.\n",
        "  faces, landmarks = model.detect(img, threshold=0.5, scale=1.0)\n",
        "  # Draw boxes around the detected faces and save the image as output_filename\n",
        "  if output_filename is not None:\n",
        "    if faces is not None:\n",
        "      #For each face, we draw a rectangle\n",
        "      for i in range(faces.shape[0]):\n",
        "        box = faces[i].astype(np.int)\n",
        "        #print(\"box =\", box)\n",
        "        cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
        "    cv2.imwrite(output_filename, img)\n",
        "  return faces, landmarks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXE5wQBk4TKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to do face detection on an image file and optionally save the\n",
        "# result to a new image file.\n",
        "# Return the faces, landmarks detected\n",
        "def detect_faces_and_save_results(input_filename, model, output_filename = None):\n",
        "  # Read the image from file\n",
        "  img = cv2.imread(input_filename)\n",
        "  return detect_faces_and_save_results_img(img, model, output_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k_XPHaNl-qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to copy out all detected faces from an image\n",
        "# Returns the detected face images in a list\n",
        "# Uses an InsightsFace utility function to align, normalize and crop the face \n",
        "# images so that they are ready for embeddings vector calculation\n",
        "def get_all_faces_in_image_img(input_image, faces, landmarks):\n",
        "  # Downscale the image if needed\n",
        "  img = downscale_image(input_image, 1280, 1280)  # Max x size = 1280, max y size = 1280\n",
        "  # Initialize an empty list\n",
        "  face_images = []\n",
        "  # Loop over the faces copying them out\n",
        "  if faces is not None:\n",
        "    #For each face, we copy it from the image\n",
        "    for i in range(faces.shape[0]):\n",
        "      # box = faces[i].astype(np.int)\n",
        "      # face_img = img[box[1]:box[3], box[0]:box[2]]  # ROI = image[y1:y2, x1:x2]\n",
        "      face_img = insightface.utils.face_align.norm_crop(img, landmarks[i])\n",
        "      face_images.append(face_img)\n",
        "  return face_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7b5UAoo6HrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to copy out all detected faces from an image\n",
        "# Returns the detected face images in a list\n",
        "def get_all_faces_in_image(input_filename, faces, landmarks):\n",
        "  # Read the image from file\n",
        "  img = cv2.imread(input_filename)\n",
        "  return get_all_faces_in_image_img(img, faces, landmarks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqfWjkFC6526",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to calculate the cosine similarity between two vectors (embeddings)\n",
        "def cosine_similarity(vec1, vec2):\n",
        "  return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFKgu7mJ-3NS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to create a directory, even > 1 level down\n",
        "def makedirs(pathname):\n",
        "  try:\n",
        "    os.makedirs(pathname, ACCESS_RIGHTS)\n",
        "  except OSError as exc:\n",
        "    if exc.errno != errno.EEXIST:\n",
        "      raise\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3fkujcZoIn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to clear all global detection flags\n",
        "def clear_all_global_detection_variables():\n",
        "  global person_max_prob_in_video\n",
        "  global cat_max_prob_in_video\n",
        "  global car_max_prob_in_video\n",
        "  global truck_max_prob_in_video\n",
        "  global motorcycle_max_prob_in_video\n",
        "  global bicycle_max_prob_in_video\n",
        "  person_max_prob_in_video = 0.0\n",
        "  cat_max_prob_in_video = 0.0\n",
        "  car_max_prob_in_video = 0.0\n",
        "  truck_max_prob_in_video = 0.0\n",
        "  motorcycle_max_prob_in_video = 0.0\n",
        "  bicycle_max_prob_in_video = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDqReOo0ATEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Define a function to process one image file\n",
        "# \n",
        "def process_image_file(input_root, output_root, processed_root, input_dir, filename):\n",
        "  #print(\"input_root\", input_root)\n",
        "  #print(\"output_root\", output_root)\n",
        "  #print(\"processed_root\", processed_root)\n",
        "  #print(\"input_dir\", input_dir)\n",
        "  #print(\"filename\", filename)\n",
        "  #input_dir = \"./input\"\n",
        "  #output_dir = \"./output\"\n",
        "  if not (filename.endswith(\".jpg\") or filename.endswith(\".jpeg\")):\n",
        "    return\n",
        "# for filename in os.listdir(input_dir):\n",
        "#   if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
        "\n",
        "  # Split out the \"middle part\" of the full input file name\n",
        "  before_sep, sep, after_sep = input_dir.partition(input_root)\n",
        "  assert before_sep == \"\"\t# Should always be \"\"\n",
        "  #print(\"after %s comes %s\" % (input_root, after_sep))\n",
        "\n",
        "  # Prepare the output_dir\n",
        "  output_dir = os.path.join(output_root, after_sep)\n",
        "  makedirs(output_dir)\n",
        "\n",
        "  # First detect objects in the image\n",
        "  input_filename = os.path.join(input_dir, filename)\n",
        "  output_filename = os.path.join(output_dir, \"predicted-objects-\"+filename)\n",
        "  print(\"Processing file:\", input_filename, \"... output_dir:\", output_dir)\n",
        "  #log_file.write(\"Image file: %s\\n\" % (input_filename))\n",
        "  try:\n",
        "#    detections = imageDetector.detectCustomObjectsFromImage(custom_objects=customObjectsImage, \n",
        "#                                                      input_image=input_filename, \n",
        "#                                                      output_image_path=output_filename, \n",
        "#                                                      minimum_percentage_probability=OBJDET_MIN_PERCENTAGE_PROBABILITY)\n",
        "    # load an image (into shared CPU/GPU memory)\n",
        "    # Outcommented -->\n",
        "    #img, width, height = jetson.utils.loadImageRGBA(input_filename)\n",
        "    #detections = objectDetector.Detect(img, width, height, OBJDET_OVERLAY_FLAG)\n",
        "    # <-- outcommented\n",
        "    detections = darknet.performDetect(imagePath = input_filename, \n",
        "                                       thresh = OBJDET_MIN_PERCENTAGE_PROBABILITY / 100.0, \n",
        "                                       configPath = os.path.join(DARKNET_PATH, DARKNET_CFG), \n",
        "                                       weightPath = os.path.join(DARKNET_PATH, DARKNET_WEIGHTS), \n",
        "                                       metaPath = os.path.join(DARKNET_PATH, DARKNET_META), \n",
        "                                       showImage = False, \n",
        "                                       makeImageOnly = False, \n",
        "                                       initOnly = False)\n",
        "    #res.append((nameTag, dets[j].prob[i], (b.x, b.y, b.w, b.h)))\n",
        "    #print(\"detections:\", detections)\n",
        "    if detections is None:\n",
        "      return\n",
        "    # print the detections\n",
        "#    print(\"  detected {:d} objects in image\".format(len(detections)))\n",
        "#    for detection in detections:\n",
        "#      print(detection)\n",
        "#      print(\"objectDetector.GetClassDesc(detection): \", objectDetector.GetClassDesc(detection.ClassID))\n",
        "  except Exception as exc:\n",
        "    print(\"  ERROR: Caught exception from darknet.performDetect: \", type(exc), exc.args)\n",
        "    log_file = open(LOGFILE_NAME, \"a+\")\n",
        "    log_file.write(\"ERROR: Caught exception when processing file %s:\" % (input_filename))\n",
        "    log_file.write(\"  Exception type: %s args: %s\" % (type(exc), exc.args))\n",
        "    log_file.close()\n",
        "    #log_file.write(\"  ERROR processing this file, skipping it.\\n\")\n",
        "    #log_file.close()\n",
        "    dest_dir = os.path.join(processed_root, PROCESSED_ERROR_SUBROOT, after_sep)\n",
        "    print(\"  Destination directory for move: \", dest_dir)\n",
        "    makedirs(dest_dir)\n",
        "    shutil.move(input_filename, dest_dir)\n",
        "    return\n",
        "\n",
        "  #print(\"  len(detections) =\", len(detections))\n",
        "\n",
        "  # Get the object detection probablilties and check if any person(s) were found\n",
        "  # We work with max probabilities since there might be more than one object of each type \n",
        "  # in each image, each with different probability\n",
        "  person_max_prob_in_image = 0.0    \n",
        "  cat_max_prob_in_image = 0.0\n",
        "  car_max_prob_in_image = 0.0\n",
        "  truck_max_prob_in_image = 0.0\n",
        "  motorcycle_max_prob_in_image = 0.0\n",
        "  bicycle_max_prob_in_image = 0.0\n",
        "  object_of_interest_in_image = False\n",
        "\n",
        "  for detection in detections:\n",
        "    #detection_name = objectDetector.GetClassDesc(detection.ClassID)\n",
        "    det_name = detection[0]\n",
        "    det_prob = detection[1]\n",
        "    det_bbox = detection[2]\n",
        "    #print(\"det_name:\", det_name, \"det_prob:\", det_prob, \"det_bbox:\", det_bbox)\n",
        "    #print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"] )\n",
        "    #log_file.write(\"%s:%.4f  \" % (eachObject[\"name\"], eachObject[\"percentage_probability\"] / 100.0))\n",
        "    if det_name == \"person\":\n",
        "      person_max_prob_in_image = max(person_max_prob_in_image, det_prob)\n",
        "      object_of_interest_in_image = True\n",
        "    elif det_name == \"cat\":\n",
        "      cat_max_prob_in_image = max(cat_max_prob_in_image, det_prob)\n",
        "      object_of_interest_in_image = True\n",
        "    elif det_name == \"car\":\n",
        "      car_max_prob_in_image = max(car_max_prob_in_image, det_prob)\n",
        "      object_of_interest_in_image = True\n",
        "    elif det_name == \"truck\":\n",
        "      truck_max_prob_in_image = max(truck_max_prob_in_image, det_prob)\n",
        "      object_of_interest_in_image = True\n",
        "    elif det_name == \"motorcycle\":\n",
        "      motorcycle_max_prob_in_image = max(motorcycle_max_prob_in_image, det_prob)\n",
        "      object_of_interest_in_image = True\n",
        "    elif det_name == \"bicycle\":\n",
        "      bicycle_max_prob_in_image = max(bicycle_max_prob_in_image, det_prob)\n",
        "      object_of_interest_in_image = True\n",
        "    #else:\n",
        "    #  print(\"  WARNING: Unexpected detection in image: \", detection)\n",
        "\n",
        "  print(\"  ObjDet: person: %.4f cat: %.4f car: %.4f truck: %.4f motorcycle: %.4f bicycle: %.4f\" %\n",
        "        (person_max_prob_in_image, cat_max_prob_in_image, car_max_prob_in_image, \n",
        "         truck_max_prob_in_image, motorcycle_max_prob_in_image, bicycle_max_prob_in_image))\n",
        "\n",
        "  p_max_similarity = -1.0\n",
        "  m_max_similarity = -1.0\n",
        "  s_max_similarity = -1.0\n",
        "  l_max_similarity = -1.0\n",
        "\n",
        "  # If person(s) are present, detect faces in the image\n",
        "  if person_max_prob_in_image > 0.0 and DO_FACE_DETECTION_VERIFICATION:\n",
        "    output_filename = os.path.join(output_dir, \"predicted-faces-\"+filename)\n",
        "    # print(filename, \"   \", input_filename, \"   \", output_filename)\n",
        "    faces, landmarks = detect_faces_and_save_results(input_filename, rf_model, output_filename)\n",
        "    # For each face found, calculate embedding vector and similarity to each reference face\n",
        "    if faces is not None:\n",
        "      face_images = get_all_faces_in_image(input_filename, faces, landmarks)\n",
        "      for i in range(len(face_images)):\n",
        "        face_embedding = af_model.get_embedding(face_images[i]).flatten()\n",
        "        p_similarity = cosine_similarity(p_face_embedding, face_embedding)\n",
        "        m_similarity = cosine_similarity(m_face_embedding, face_embedding)\n",
        "        s_similarity = cosine_similarity(s_face_embedding, face_embedding)\n",
        "        l_similarity = cosine_similarity(l_face_embedding, face_embedding)\n",
        "        #log_file.write(\"  FaceVer: face %d similarity: p: %.4f m: %.4f s: %.4f l: %.4f\\n\" %\n",
        "        #               (i, p_similarity, m_similarity, s_similarity, l_similarity))\n",
        "        p_max_similarity = max(p_max_similarity, p_similarity)\n",
        "        m_max_similarity = max(m_max_similarity, m_similarity)\n",
        "        s_max_similarity = max(s_max_similarity, s_similarity)\n",
        "        l_max_similarity = max(l_max_similarity, l_similarity)\n",
        "        if IN_COLAB:\n",
        "          pyplot.imshow(face_images[i])\n",
        "          pyplot.show()\n",
        "      print(\"  FaceVer: max similarity scores: p: %.4f m: %.4f s: %.4f l: %.4f\" %\n",
        "            (p_max_similarity, m_max_similarity, s_max_similarity, l_max_similarity))\n",
        "\n",
        "  # Move the file to the proper destination\n",
        "  if object_of_interest_in_image:\n",
        "    # Object found, move accordingly\n",
        "    dest_dir = os.path.join(processed_root, PROCESSED_POS_OBJDET_SUBROOT, after_sep)\n",
        "  else:\n",
        "    # Object not found, move accordingly\n",
        "    dest_dir = os.path.join(processed_root, PROCESSED_NEG_OBJDET_SUBROOT, after_sep)\n",
        "  print(\"  Destination directory for move: \", dest_dir)\n",
        "  makedirs(dest_dir)\n",
        "  shutil.move(input_filename, dest_dir)\n",
        "  moved_filename = os.path.join(dest_dir, filename)\n",
        "\n",
        "  # Write a row to the log file, format:\n",
        "  # \"FileDate;FileTime;FileType;ODPerson;ODCat;ODCar;ODTruck;ODMotorcycle;ODBicycle;FV_P;FV_M;FV_S;FV_L;FileName\\n\"\n",
        "  file_mod_time = time.localtime(os.path.getmtime(moved_filename))\n",
        "  file_date = time.strftime(\"%Y-%m-%d\", file_mod_time)\n",
        "  file_time = time.strftime(\"%H:%M:%S\", file_mod_time)\n",
        "  csv_file = open(CSVFILE_NAME, \"a+\")\n",
        "  csv_file.write(\"%s;%s;%s;%.4f;%.4f;%.4f;%.4f;%.4f;%.4f;%.4f;%.4f;%.4f;%.4f;%s\\n\" %\n",
        "      (file_date, file_time, \"image\", person_max_prob_in_image, cat_max_prob_in_image, \n",
        "       car_max_prob_in_image, truck_max_prob_in_image, motorcycle_max_prob_in_image, \n",
        "       bicycle_max_prob_in_image, p_max_similarity, m_max_similarity, s_max_similarity, \n",
        "       l_max_similarity, moved_filename))\n",
        "  csv_file.close()\n",
        "\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE_NSqYHJgkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Define a function to process one video file\n",
        "# Do object and face detection and save \n",
        "# the results in an output directory. Then calculate embedding vector for each\n",
        "# found face, and the similarity to each reference face, print the results\n",
        "# \n",
        "def process_video_file(input_root, output_root, processed_root, input_dir, filename):\n",
        "  #print(\"input_root\", input_root)\n",
        "  #print(\"output_root\", output_root)\n",
        "  #print(\"processed_root\", processed_root)\n",
        "  #print(\"input_dir\", input_dir)\n",
        "  #print(\"filename\", filename)\n",
        "\n",
        "  if not filename.endswith(\".mp4\"):\n",
        "    return\n",
        "\n",
        "  # Split out the \"middle part\" of the full input file name\n",
        "  before_sep, sep, after_sep = input_dir.partition(input_root)\n",
        "  assert before_sep == \"\"\t# Should always be \"\"\n",
        "  #print(\"after %s comes %s\" % (input_root, after_sep))\n",
        "\n",
        "  # Prepare the output_dir\n",
        "  output_dir = os.path.join(output_root, after_sep)\n",
        "  makedirs(output_dir)\n",
        "\n",
        "  # Clear the video object detection variables\n",
        "  person_max_prob_in_video = 0.0    \n",
        "  cat_max_prob_in_video = 0.0\n",
        "  car_max_prob_in_video = 0.0\n",
        "  truck_max_prob_in_video = 0.0\n",
        "  motorcycle_max_prob_in_video = 0.0\n",
        "  bicycle_max_prob_in_video = 0.0\n",
        "  object_of_interest_in_video = False\n",
        "\n",
        "  # First detect objects in the video\n",
        "  input_filename = os.path.join(input_dir, filename)\n",
        "  output_filename = os.path.join(output_dir, \"predicted-objects-\"+filename)\n",
        "  print(\"Processing video file:\", input_filename, \"... output_dir:\", output_dir)\n",
        "  #log_file.write(\"Video file: %s\\n\" % (input_filename))\n",
        "\n",
        "  # Open the video file\n",
        "  cap = cv2.VideoCapture()\n",
        "  cap.open(input_filename)\n",
        "  #width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  #height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "  # We optimize the run-time performance by not processing each frame of the video\n",
        "  frame_counter = 0\n",
        "  while True:\n",
        "    (rv, cv2_im) = cap.read()   # im is a valid image if and only if rv is true\n",
        "    if not rv:              # we reached the end of video file\n",
        "      cap.release()\n",
        "      break\n",
        "\n",
        "    if (frame_counter % OBJDET_VIDEO_FRAME_SKIP_RATE) == 0:\n",
        "      # Process this frame\n",
        "      # Write the frame to a temp image file: OBJDET_TEMP_IMAGE_FILENAME\n",
        "      cv2.imwrite(OBJDET_TEMP_IMAGE_FILENAME, cv2_im)\n",
        "      # load an image (into shared CPU/GPU memory)\n",
        "      #img, width, height = jetson.utils.loadImageRGBA(OBJDET_TEMP_IMAGE_FILENAME)\n",
        "      try:\n",
        "        #detections = objectDetector.Detect(img, width, height, OBJDET_OVERLAY_FLAG)\n",
        "        detections = darknet.performDetect(imagePath = OBJDET_TEMP_IMAGE_FILENAME, \n",
        "                                           thresh = OBJDET_MIN_PERCENTAGE_PROBABILITY / 100.0, \n",
        "                                           configPath = os.path.join(DARKNET_PATH, DARKNET_CFG), \n",
        "                                           weightPath = os.path.join(DARKNET_PATH, DARKNET_WEIGHTS), \n",
        "                                           metaPath = os.path.join(DARKNET_PATH, DARKNET_META), \n",
        "                                           showImage = False, \n",
        "                                           makeImageOnly = False, \n",
        "                                           initOnly = False)\n",
        "        #res.append((nameTag, dets[j].prob[i], (b.x, b.y, b.w, b.h)))\n",
        "        #print(\"detections:\", detections)\n",
        "      except Exception as exc:\n",
        "        print(\"  ERROR: Caught exception from darknet.performDetect: \", type(exc), exc.args)\n",
        "        #log_file.write(\"  ERROR processing this file, skipping it.\\n\")\n",
        "        #log_file.close()\n",
        "        log_file = open(LOGFILE_NAME, \"a+\")\n",
        "        log_file.write(\"ERROR: Caught exception when processing file %s:\" % (input_filename))\n",
        "        log_file.write(\"  Exception type: %s args: %s\" % (type(exc), exc.args))\n",
        "        log_file.close()\n",
        "\n",
        "        dest_dir = os.path.join(processed_root, PROCESSED_ERROR_SUBROOT, after_sep)\n",
        "        print(\"  Destination directory for move: \", dest_dir)\n",
        "        makedirs(dest_dir)\n",
        "        shutil.move(input_filename, dest_dir)\n",
        "        cap.release()\n",
        "        return\n",
        "\n",
        "      # print the detections\n",
        "      #print(\"  detected {:d} objects in image\".format(len(detections)))\n",
        "      #for detection in detections:\n",
        "      #  print(detection)\n",
        "      #  print(\"objectDetector.GetClassDesc(detection): \", objectDetector.GetClassDesc(detection.ClassID))\n",
        "\n",
        "      for detection in detections:\n",
        "        #detection_name = objectDetector.GetClassDesc(detection.ClassID)\n",
        "        det_name = detection[0]\n",
        "        det_prob = detection[1]\n",
        "        det_bbox = detection[2]\n",
        "        #print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"] )\n",
        "        #log_file.write(\"%s:%.4f  \" % (eachObject[\"name\"], eachObject[\"percentage_probability\"] / 100.0))\n",
        "        if det_name == \"person\":\n",
        "          person_max_prob_in_video = max(person_max_prob_in_video, det_prob)\n",
        "          object_of_interest_in_video = True\n",
        "        elif det_name == \"cat\":\n",
        "          cat_max_prob_in_video = max(cat_max_prob_in_video, det_prob)\n",
        "          object_of_interest_in_video = True\n",
        "        elif det_name == \"car\":\n",
        "          car_max_prob_in_video = max(car_max_prob_in_video, det_prob)\n",
        "          object_of_interest_in_video = True\n",
        "        elif det_name == \"truck\":\n",
        "          truck_max_prob_in_video = max(truck_max_prob_in_video, det_prob)\n",
        "          object_of_interest_in_video = True\n",
        "        elif det_name == \"motorcycle\":\n",
        "          motorcycle_max_prob_in_video = max(motorcycle_max_prob_in_video, det_prob)\n",
        "          object_of_interest_in_video = True\n",
        "        elif det_name == \"bicycle\":\n",
        "          bicycle_max_prob_in_video = max(bicycle_max_prob_in_video, det_prob)\n",
        "          object_of_interest_in_video = True\n",
        "    frame_counter += 1\n",
        "\n",
        "  # At the end of video processing, the callbackForFull function will have been called\n",
        "  # setting the global flags according to what was detected in the video\n",
        "  print(\"  ObjDet: person: %.4f cat: %.4f car: %.4f truck: %.4f motorcycle: %.4f bicycle: %.4f\" %\n",
        "    (person_max_prob_in_video, cat_max_prob_in_video, car_max_prob_in_video, \n",
        "     truck_max_prob_in_video, motorcycle_max_prob_in_video, bicycle_max_prob_in_video))\n",
        "\n",
        "  p_max_similarity = -1.0\n",
        "  m_max_similarity = -1.0\n",
        "  s_max_similarity = -1.0\n",
        "  l_max_similarity = -1.0\n",
        "\n",
        "  # If person(s) were detected, detect faces in the image\n",
        "  if DO_FACE_DETECTION_VERIFICATION and person_max_prob_in_video > 0.0:\n",
        "    # First initialize the video reading\n",
        "    cap = cv2.VideoCapture()\n",
        "    cap.open(input_filename)\n",
        "    #width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    #height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    #size = (width,height)\n",
        "\n",
        "    # We optimize the run-time performance by not processing each frame of the video\n",
        "    frame_counter = 0\n",
        "    while True:\n",
        "      (rv, im) = cap.read()   # im is a valid image if and only if rv is true\n",
        "      if not rv:              # we reached the end of video file\n",
        "        cap.release()\n",
        "        break\n",
        "\n",
        "      if (frame_counter % FACEDET_FRAME_SKIP_RATE) == 0:\n",
        "        # Process this frame\n",
        "        output_filename = os.path.join(output_dir, \"predicted-faces-\"+filename+\"-frm\"+str(frame_counter)+\".jpg\")\n",
        "        #print(\"output_filename =\", output_filename)\n",
        "        faces, landmarks = detect_faces_and_save_results_img(im, rf_model, output_filename)\n",
        "        # For each face found, calculate embedding vector and similarity to each reference face\n",
        "        if faces is not None:\n",
        "          face_images = get_all_faces_in_image_img(im, faces, landmarks)\n",
        "          for i in range(len(face_images)):\n",
        "            face_embedding = af_model.get_embedding(face_images[i]).flatten()\n",
        "            p_similarity = cosine_similarity(p_face_embedding, face_embedding)\n",
        "            m_similarity = cosine_similarity(m_face_embedding, face_embedding)\n",
        "            s_similarity = cosine_similarity(s_face_embedding, face_embedding)\n",
        "            l_similarity = cosine_similarity(l_face_embedding, face_embedding)\n",
        "            #print(\"   Face \", i, \"similarity scores: p:\", p_similarity, \n",
        "            #      \"m:\", m_similarity, \"s:\", s_similarity, \"l:\", l_similarity)\n",
        "            #pyplot.imshow(face_images[i])\n",
        "            #pyplot.show()\n",
        "            p_max_similarity = max(p_max_similarity, p_similarity)\n",
        "            m_max_similarity = max(m_max_similarity, m_similarity)\n",
        "            s_max_similarity = max(s_max_similarity, s_similarity)\n",
        "            l_max_similarity = max(l_max_similarity, l_similarity)\n",
        "            #log_file.write(\"  FaceVer: face %d similarity: p: %.4f m: %.4f s: %.4f l: %.4f\\n\" %\n",
        "            #               (i, p_similarity, m_similarity, s_similarity, l_similarity))\n",
        "      frame_counter += 1\n",
        "\n",
        "    # Print out the max similarity for this video\n",
        "    print(\"  FaceVer: max similarity scores: p: %.4f m: %.4f s: %.4f l: %.4f\" %\n",
        "          (p_max_similarity, m_max_similarity, s_max_similarity, l_max_similarity))\n",
        "    #log_file.write(\"  FaceVer: max similarity: p: %.4f m: %.4f s: %.4f l: %.4f\\n\" %\n",
        "    #               (p_max_similarity, m_max_similarity, s_max_similarity, l_max_similarity))\n",
        "    # End if\n",
        "\n",
        "  # Move the file to the proper destination\n",
        "  if object_of_interest_in_video:\n",
        "    # Object found, move accordingly\n",
        "    dest_dir = os.path.join(processed_root, PROCESSED_POS_OBJDET_SUBROOT, after_sep)\n",
        "  else:\n",
        "    # Object not found, move accordingly\n",
        "    dest_dir = os.path.join(processed_root, PROCESSED_NEG_OBJDET_SUBROOT, after_sep)\n",
        "  print(\"  Destination directory for move: \", dest_dir)\n",
        "  makedirs(dest_dir)\n",
        "  shutil.move(input_filename, dest_dir)\n",
        "  moved_filename = os.path.join(dest_dir, filename)\n",
        "\n",
        "  # Write a row to the log file, format:\n",
        "  # \"FileDate;FileTime;FileType;ODPerson;ODCat;ODCar;ODTruck;ODMotorcycle;ODBicycle;FV_P;FV_M;FV_S;FV_L;FileName\\n\"\n",
        "  file_mod_time = time.localtime(os.path.getmtime(moved_filename))\n",
        "  file_date = time.strftime(\"%Y-%m-%d\", file_mod_time)\n",
        "  file_time = time.strftime(\"%H:%M:%S\", file_mod_time)\n",
        "  csv_file = open(CSVFILE_NAME, \"a+\")\n",
        "  csv_file.write(\"%s;%s;%s;%.4f;%.4f;%.4f;%.4f;%.4f;%.4f;%.4f;%.4f;%.4f;%.4f;%s\\n\" %\n",
        "      (file_date, file_time, \"video\", person_max_prob_in_video, cat_max_prob_in_video, \n",
        "       car_max_prob_in_video, truck_max_prob_in_video, motorcycle_max_prob_in_video, \n",
        "       bicycle_max_prob_in_video, p_max_similarity, m_max_similarity, s_max_similarity, \n",
        "       l_max_similarity, moved_filename))\n",
        "  csv_file.close()\n",
        "\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpm3bSfutFvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to process one file tree\n",
        "def process_file_tree(input_root, output_root, processed_root):\n",
        "  num_images_processed = 0\n",
        "  num_videos_processed = 0\n",
        "  # Walk through the input_root tree\n",
        "  for dir_name, subdir_list, file_list in os.walk(input_root):\n",
        "    print(\"Found directory:\", dir_name)\n",
        "    #before_sep, sep, after_sep = dir_name.partition(INPUT_ROOT)\n",
        "    #assert before_sep == \"\"\t# Should always be \"\"\n",
        "    #print(\"before_sep: \", before_sep, \" sep: \", sep, \" after_sep: \", after_sep)\n",
        "    #make_dirs(OUTPUT_ROOT+after_sep)\n",
        "    print(\"Found subdirs:\")\n",
        "    for subdirname in subdir_list:\n",
        "      print(\"\\t%s\" % subdirname)\n",
        "    print(\"Found files:\")\n",
        "    for filename in file_list:\n",
        "      print(\"\\t%s\" % filename)\n",
        "    print(\"Processing image files...\")\n",
        "    for filename in file_list:\n",
        "      if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
        "        process_image_file(input_root, output_root, processed_root, dir_name, filename)\n",
        "        num_images_processed += 1\n",
        "    print(\"Processing video files...\")\n",
        "    for filename in file_list:\n",
        "      if filename.endswith(\".mp4\"):\n",
        "        process_video_file(input_root, output_root, processed_root, dir_name, filename)\n",
        "        num_videos_processed += 1\n",
        "  return num_images_processed, num_videos_processed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyVc1PaS-IzE",
        "colab_type": "text"
      },
      "source": [
        "## Main program flow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfdbNUpTIkkc",
        "colab_type": "text"
      },
      "source": [
        "### Preparation & initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcUPtJ6GZ_U9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare for Object Detection by loading the Object Detection model\n",
        "# The second argument should look like this:\n",
        "#   ['./PF-detectnet-console.py', '--network=ssd-inception-v2', 'images/peds_0.jpg', 'peds_0_output.jpg']\n",
        "#argv = [sys.argv[0], \"--network=\"+OBJDET_JETSON_MODEL_TO_USE, \"dummy.jpg\", \"dummy-output.jpg\"]\n",
        "\"\"\"\n",
        "argv = [sys.argv[0], \"--network=\"+OBJDET_JETSON_MODEL_TO_USE, \"--threshold=\"+str(OBJDET_MIN_PERCENTAGE_PROBABILITY / 100.0)]\n",
        "print(\"argv:\", argv)\n",
        "objectDetector = jetson.inference.detectNet(OBJDET_JETSON_MODEL_TO_USE, \n",
        "                                            argv,\n",
        "                                            OBJDET_MIN_PERCENTAGE_PROBABILITY / 100.0)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYeK83Zzp5C0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get RetinaFace model by name\n",
        "if DO_FACE_DETECTION_VERIFICATION:\n",
        "  rf_model = insightface.model_zoo.get_model('retinaface_r50_v1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDAOP0CBi4Ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get ArcFace model by name\n",
        "if DO_FACE_DETECTION_VERIFICATION:\n",
        "  af_model = insightface.model_zoo.get_model('arcface_r100_v1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHPXYTkDqOiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the environment, to use GPU or CPU to detect & compute embeddings for the faces for all incoming images.\n",
        "# The nms threshold is set to 0.4 in this example.\n",
        "if DO_FACE_DETECTION_VERIFICATION:\n",
        "  if USE_GPU:\n",
        "    CTX_ID = 0\n",
        "  else:\n",
        "    CTX_ID = -1\n",
        "\n",
        "  rf_model.prepare(ctx_id = CTX_ID, nms=0.4)\n",
        "  af_model.prepare(ctx_id = CTX_ID)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4a21iMUjtRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference images have fixed names, detect the reference faces\n",
        "if DO_FACE_DETECTION_VERIFICATION:\n",
        "  p_faces, p_landmarks = detect_faces_and_save_results(\"p.jpg\", rf_model, \"predicted-p.jpg\")\n",
        "  m_faces, m_landmarks = detect_faces_and_save_results(\"m.jpg\", rf_model, \"predicted-m.jpg\")\n",
        "  s_faces, s_landmarks = detect_faces_and_save_results(\"s.jpg\", rf_model, \"predicted-s.jpg\")\n",
        "  l_faces, l_landmarks = detect_faces_and_save_results(\"l.jpg\", rf_model, \"predicted-l.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xd4B3ISyzHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the faces and save them in one list per reference\n",
        "if DO_FACE_DETECTION_VERIFICATION:\n",
        "  p_face_images = get_all_faces_in_image(\"p.jpg\", p_faces, p_landmarks)\n",
        "  m_face_images = get_all_faces_in_image(\"m.jpg\", m_faces, m_landmarks)\n",
        "  s_face_images = get_all_faces_in_image(\"s.jpg\", s_faces, s_landmarks)\n",
        "  l_face_images = get_all_faces_in_image(\"l.jpg\", l_faces, l_landmarks)\n",
        "\n",
        "  # We expect only one face per image for the reference images\n",
        "  assert len(p_face_images) == 1\n",
        "  assert len(m_face_images) == 1\n",
        "  assert len(s_face_images) == 1\n",
        "  assert len(l_face_images) == 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_O8vYJ-yyl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the faces as new image files (for inspection)\n",
        "if DO_FACE_DETECTION_VERIFICATION:\n",
        "  cv2.imwrite(\"detected-face-p.jpg\", p_face_images[0])\n",
        "  cv2.imwrite(\"detected-face-m.jpg\", m_face_images[0])\n",
        "  cv2.imwrite(\"detected-face-s.jpg\", s_face_images[0])\n",
        "  cv2.imwrite(\"detected-face-l.jpg\", l_face_images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvBF1ixtFSN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the 512D embedding vectors for the reference (known) faces\n",
        "if DO_FACE_DETECTION_VERIFICATION:\n",
        "  p_face_embedding = af_model.get_embedding(p_face_images[0]).flatten()\n",
        "  m_face_embedding = af_model.get_embedding(m_face_images[0]).flatten()\n",
        "  s_face_embedding = af_model.get_embedding(s_face_images[0]).flatten()\n",
        "  l_face_embedding = af_model.get_embedding(l_face_images[0]).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntrTWIW9Ixz3",
        "colab_type": "text"
      },
      "source": [
        "### Main processing loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKpSp7vLeTd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loop over all .jpg files in an input directory, do face detection and save \n",
        "# the results in an output directory. Then calculate embedding vector for each\n",
        "# found face, and the similarity to each reference face, print the results\n",
        "\n",
        "\"\"\"\n",
        "# Debug:\n",
        "for tree_list in PROCESSING_TREES:\n",
        "  print(\"Entry 1:\")\n",
        "  print(\"  input_tree:\", tree_list[0])\n",
        "  print(\"  output_tree:\", tree_list[1])\n",
        "  print(\"  processed_tree:\", tree_list[2])\n",
        "\"\"\"\n",
        "\n",
        "#logfile_name = LOGFILE_NAME   # os.path.join(OUTPUT_ROOT, LOGFILE_NAME)\n",
        "#print(\"Log file name: \", logfile_name)\n",
        "\n",
        "# Check if the CSV file exists, if not create it\n",
        "if not os.path.isfile(CSVFILE_NAME):\n",
        "  # Write the headings to the CSV file\n",
        "  csv_file = open(CSVFILE_NAME, \"a+\")\n",
        "  csv_file.write(\"FileDate;FileTime;FileType;ODPerson;ODCat;ODCar;ODTruck;ODMotorcycle;ODBicycle;FV_P;FV_M;FV_S;FV_L;FileName\\n\")\n",
        "  csv_file.close()\n",
        "\n",
        "\n",
        "while True:\n",
        "  try:\n",
        "    # Get the start time\n",
        "    start_time = datetime.datetime.now()\n",
        "\n",
        "    # Write the start time and headings to the log file\n",
        "    log_file = open(LOGFILE_NAME, \"a+\")\n",
        "    log_file.write(\"---------------------------------\\n\")\n",
        "    log_file.write(\"Start processing at: %s\\n\" % (start_time))\n",
        "    log_file.close()\n",
        "\n",
        "    # Initialize counters\n",
        "    num_images_processed = 0\n",
        "    num_videos_processed = 0\n",
        "\n",
        "    # Loop over the defined file structures to process, and do the processing\n",
        "    for tree_list in PROCESSING_TREES:\n",
        "      input_root = tree_list[0]\n",
        "      output_root = tree_list[1]\n",
        "      processed_root = tree_list[2]\n",
        "      num_images, num_videos = process_file_tree(input_root, output_root, processed_root)\n",
        "      num_images_processed += num_images\n",
        "      num_videos_processed += num_videos\n",
        "\n",
        "    \"\"\"\n",
        "    # Walk through the INPUT_ROOT tree  --> Now converted into function process_file_tree(...)\n",
        "    for dir_name, subdir_list, file_list in os.walk(INPUT_ROOT):\n",
        "      print(\"Found directory:\", dir_name)\n",
        "      #before_sep, sep, after_sep = dir_name.partition(INPUT_ROOT)\n",
        "      #assert before_sep == \"\"\t# Should always be \"\"\n",
        "      #print(\"before_sep: \", before_sep, \" sep: \", sep, \" after_sep: \", after_sep)\n",
        "      #make_dirs(OUTPUT_ROOT+after_sep)\n",
        "      print(\"Found subdirs:\")\n",
        "      for subdirname in subdir_list:\n",
        "        print(\"\\t%s\" % subdirname)\n",
        "      print(\"Found files:\")\n",
        "      for filename in file_list:\n",
        "        print(\"\\t%s\" % filename)\n",
        "      print(\"Processing image files...\")\n",
        "      for filename in file_list:\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
        "          process_image_file(INPUT_ROOT, OUTPUT_ROOT, PROCESSED_ROOT, dir_name, filename, logfile_name)\n",
        "          num_images_processed += 1\n",
        "      print(\"Processing video files...\")\n",
        "      for filename in file_list:\n",
        "        if filename.endswith(\".mp4\"):\n",
        "          process_video_file(INPUT_ROOT, OUTPUT_ROOT, PROCESSED_ROOT, dir_name, filename, logfile_name)\n",
        "          num_videos_processed += 1\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the end time and calculate the processing time\n",
        "    end_time = datetime.datetime.now()\n",
        "    processing_time = end_time - start_time\n",
        "\n",
        "    # Write the end time to the log file\n",
        "    log_file = open(LOGFILE_NAME, \"a+\")\n",
        "    log_file.write(\"End processing at: %s\\n\" % (end_time))\n",
        "    log_file.write(\"Processed %d images and %d videos in: %s\\n\" % (num_images_processed, num_videos_processed, processing_time))\n",
        "    log_file.close()\n",
        "\n",
        "    # Sleep for a minute if nothing was processed\n",
        "    if num_images_processed == 0 and num_videos_processed == 0:\n",
        "      time.sleep(60)\n",
        "  except Exception as exc:\n",
        "    print(\"ERROR: Caught exception from main processing loop: \", type(exc), exc.args, file=sys.stderr)\n",
        "    print(\"       Sleeping for 5 minutes before resuming...\", file=sys.stderr)\n",
        "    time.sleep(5 * 60)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}